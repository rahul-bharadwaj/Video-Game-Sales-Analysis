---
title: "Video Game Sales"
author: "Rahul Bharadwaj Mysore Venkatesh"
date: "23/08/2020"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE,
                      warning = FALSE,
                      fig.pos = 'H',
                      fig.align = 'center')
```

# **Introduction -**
Having played tons of games on PC and Playstation2 as a kid, it was a moment of nostalgia as I found a Kaggle dataset on Video Game Sales. I couldn't wait to get a hands on overview of this data which has over 15000 observations and sales for most of the games on all platforms. Note that this data is all about the number of copies sold and not about the revenue generated through sales. After all, its not always about money and this is an effort to analyze the popularity of games through number of copies sold! All values are in millions of copies sold. Let's dive in and check out which game, publisher, and platforms were most popular among gaming fans!

* We first load the libraries required for our analysis.
```{r Library, echo = TRUE}
#loading libraries
library(tidyverse)
library(visdat)
library(kableExtra)
library(ggpubr)
```

* We now read our data into R environment from a [source file](https://www.kaggle.com/gregorut/videogamesales)

* The raw data in the form of csv looks as follows.

```{r ReadData, echo = TRUE}
#reading video games sales data from csv file
vgsales <- read.csv("vgsales.csv")
#displaying dimensions of data and sample observations
glimpse(vgsales)
```

# **Initial Data Analysis -**

* Initial Data Analysis is a process which helps one get a feel of the data in question. This helps us have an overview of the data and gives insights about potential Exlporatory Data Analyis (EDA).

* Initial data analysis is the process of data inspection steps to be carried out after the research plan and data collection have been finished but before formal statistical analyses. The purpose is to minimize the risk of incorrect or misleading results. [Link for more info](https://www.sciencedirect.com/science/article/pii/S0022522315017948#:~:text=Initial%20data%20analysis%20is%20the,of%20incorrect%20or%20misleading%20results.)

* IDA can be divided into 3 main steps:
  + Data cleaning is the identification of inconsistencies in the data and the resolution of any such issues.
  + Data screening is the description of the data properties.
  + Documentation and reporting preserve the information for the later statistical analysis and models.
  
### visdat

1. The visdat package in R helps us get a visual overview of the data in the form of plots. The vis_dat() function helps us get a glimpse of the data types for all variables in our dataset.

```{r visdat, fig.cap='Visulaization of Data Types of the data', fig.height = 2, fig.width = 4}
#Initial Data Analysis to get a feel of the dataset
visdat::vis_dat(vgsales)
```
* We can observe that there are only three Types of data in our dataset viz, character, integer, and numeric. This makes it pretty straightforward and simple to conduct analysis.

\newpage
### visguess

2. The vis_guess() function tries to predict the kind of data in each cell of our dataset.

```{r visguess, fig.cap='Data Type for each cell in dataset', fig.height = 3, fig.width = 4}
#cell data type guess
visdat::vis_guess(vgsales)
```
  
* We can thus oobserve the following from the dataset.
  + Rank is integer Type.
  + Name is character Type.
  + Platform is character Type with an exception of one cell value which might have an integer.
  + Year is integer Type with some excpetion that might look like character.
  + Genre and Publisher are character Type.
  + The rest of the sales variables are either integer or double.  
* Note that this is a cell-wise interpretation and the actual data will have only one type for one column.

\newpage
### vismiss

3. The vis_miss() function give an overall visual of the missing data in our data set.

```{r vismiss, fig.cap='Missing Values Plot', fig.height = 5, fig.width = 5}
#NA or missing values viz
visdat::vis_miss(vgsales)
```
  
* We can observe that there is no missing values in our data. Present 100% indicates the same. This means we do not have to deal with missing values.

\newpage
### viscor

4. The vis_cor() function gives us a visual plot of the correlation between variables in our dataset. An important thing to note here is that it takes only numeric variables. We have already established this, thanks to vis_dat(). So we select only the numeric columns for this function.

```{r viscor, fig.cap='Correlation Plot for variables', fig.height = 3, fig.width = 5}
#visual correlation for numerical variables
visdat::vis_cor(vgsales[7:11])
```
* The above figure shows correlation as a range between +1.0 and -1.0 for the different variables.

### gathercor

5. The gather_cor() function gives us the exact values for the same instead of a range.
```{r gathercor, fig.cap='Correlation between variables'}
#tabular correlation for numerical variables
visdat::gather_cor(vgsales[7:11]) %>% filter(row_1 == "Global_Sales") %>% head(5) %>%
  kable() %>% kable_styling(full_width = FALSE)
```

* The above table shows the exact correlations between the variables in our dataset. This sample table is filtered to show the correlation between Global Sales and Sales in each major locations of the world.

\newpage

# **Exploratory Data Analysis -**

* In statistics, exploratory data analysis is an approach to analyzing data sets to summarize their main characteristics, often with visual methods. A statistical model can be used or not, but primarily EDA is for seeing what the data can tell us beyond the formal modeling or hypothesis testing task [(Wikipedia)](https://en.wikipedia.org/wiki/Exploratory_data_analysis)

## Regional Sales -

* As the data has regional sales, this was the first question I could think of. What regions drove most of the global sales?

* Let us consider the Correlation between sales in different regions and global sales as mentioned in the previous table. We plot with Regional Sales on x-axis and Global Sales on y-axis and check how each regional sales drive global sales.

```{r RegionSmooth, fig.cap='Smoothened curves for Regional Sales and Global Sales'}
NAS <- vgsales %>% ggplot(aes(x = NA_Sales, y = Global_Sales)) + geom_point() +
  geom_smooth() + xlab("North America Sales") + ylab("Global Sales")

EUS <- vgsales %>% ggplot(aes(x = EU_Sales, y = Global_Sales)) + geom_point() +
  geom_smooth() + xlab("Europe Sales") + ylab("Global Sales")

JPS <- vgsales %>% ggplot(aes(x = JP_Sales, y = Global_Sales)) + geom_point() +
  geom_smooth() + xlab("Japan Sales") + ylab("Global Sales")

ORS <- vgsales %>% ggplot(aes(x = Other_Sales, y = Global_Sales)) + geom_point() +
  geom_smooth() + xlab("Other Region Sales") + ylab("Global Sales")

ggarrange(NAS, EUS, JPS,ORS)
```
  
* The above plot is a smoothened curve of all the observations and how the tend to change.

\newpage
* The following correlation displays the above table as a plot with all the exact values.

```{r RegionCor, fig.cap='A plot of Correlation between Regional Sales and Global Sales'}
NASCor <- ggscatter(vgsales, x = "NA_Sales", y = "Global_Sales", 
          add = "reg.line", cor.coef = TRUE, cor.method = "pearson",
          xlab = "North America Sales", ylab = "Global Sales")

EUSCor <- ggscatter(vgsales, x = "EU_Sales", y = "Global_Sales", 
          add = "reg.line", cor.coef = TRUE, cor.method = "pearson",
          xlab = "Europe Sales", ylab = "Global Sales")

JPSCor <- ggscatter(vgsales, x = "JP_Sales", y = "Global_Sales", 
          add = "reg.line", cor.coef = TRUE, cor.method = "pearson",
          xlab = "Japan Sales", ylab = "Global Sales")

ORSCor <- ggscatter(vgsales, x = "Other_Sales", y = "Global_Sales", 
          add = "reg.line", cor.coef = TRUE, cor.method = "pearson",
          xlab = "Other Region Sales", ylab = "Global Sales")

ggarrange(NASCor, EUSCor, JPSCor, ORSCor)
```

* We can observe that most of the global sales share is from North America and Europe. Other regions of the world has a lesser share and Japan has the least share of global sales.

\newpage
## Famous Gaming Franchises -

* It's time to compare some of my favorite franchises from my childhood! Which franchise was more popular and on which platform?

* Let us consider some of the most famous game franchises and check what franchise sold most on what gaming platform. **The considered franchises are Grand Theft Auto, FIFA, Pokemon, Mario, Need for Speed, and Call of Duty.** These are the ones I could think of instantaneously.

```{r AllTimeSales, fig.cap='All Time Global Sales (millions)'}
GTA <- vgsales %>% filter(str_detect(vgsales$Name, "Grand Theft Auto")) %>% 
  ggplot(aes(x = reorder(Platform, -Global_Sales), y = Global_Sales, fill = Platform)) +
  geom_bar(stat = "identity", show.legend = FALSE) + xlab("Platform") + ylab("Global Sales") +
  ggtitle("Grand Theft Auto") + coord_flip()

FIFA <- vgsales %>% filter(str_detect(vgsales$Name, "FIFA")) %>% 
  ggplot(aes(x = reorder(Platform, -Global_Sales), y = Global_Sales, fill = Platform)) +
  geom_bar(stat = "identity", show.legend = FALSE) + xlab("Platform") + ylab("Global Sales") +
  ggtitle("FIFA") + coord_flip()

Pokemon <- vgsales %>% filter(str_detect(vgsales$Name, "Pokemon")) %>% 
  ggplot(aes(x = reorder(Platform, -Global_Sales), y = Global_Sales, fill = Platform)) +
  geom_bar(stat = "identity", show.legend = FALSE) + xlab("Platform") + ylab("Global Sales") +
  ggtitle("Pokemon") + coord_flip()

Mario <- vgsales %>% filter(str_detect(vgsales$Name, "Mario")) %>% 
  ggplot(aes(x = reorder(Platform, -Global_Sales), y = Global_Sales, fill = Platform)) +
  geom_bar(stat = "identity", show.legend = FALSE) + xlab("Platform") + ylab("Global Sales") +
  ggtitle("Mario") + coord_flip()

NFS <- vgsales %>% filter(str_detect(vgsales$Name, c("Need for", "Need For"))) %>% 
  ggplot(aes(x = reorder(Platform, -Global_Sales), y = Global_Sales, fill = Platform)) +
  geom_bar(stat = "identity", show.legend = FALSE) + xlab("Platform") + ylab("Global Sales") +
  ggtitle("Need For Speed") + coord_flip()

COD <- vgsales %>% filter(str_detect(vgsales$Name, c("Call of", "Call Of"))) %>% 
  ggplot(aes(x = reorder(Platform, -Global_Sales), y = Global_Sales, fill = Platform)) +
  geom_bar(stat = "identity", show.legend = FALSE) + xlab("Platform") + ylab("Global Sales") +
  ggtitle("Call Of Duty") + coord_flip()

ggarrange(GTA, FIFA, Pokemon, Mario, NFS, COD)
```

* The above barplot displays global sales on x-axis and platform of game on y-axis. We can get an overview of which franchise of games was sold on what platforms and also about the number of copies sold in millions. This can be compared side-by-side and it clearly shows which game was most popular on what platform.

* Notice that the scales are different for each franchise and **Mario has sold the most with more than 100 million copies** while **Need For Speed has sold a little over 15 million only.**

* In terms of revenue and profits generated, this might not hold good. A cheaper videogame sold in more numbers might still generate less revenue than an expensive videogame sold in lesser numbers. Something to keep in mind! Also the cost of the games definitely affect the number of copies sold.

\newpage
## UbiSoft Franchises -

* The following graph shows a dot plot of two popular game franchises of UbiSoft namely, **Assassin's Creed and Prince of Persia**. It displays global sales on x-axis and game title on the y-axis. The different colors of dots account to the type of platform the game belonged to.

* Prince of Persia (PoP) was one of my most favorite gaming franchise as a kid and I remember having played it for days together, endlessly, during my vacations. There was a time when the PoP games saw a decline over Assassin's Creed. I wanted to know why! And thus, this comparison.

```{r ACSales, fig.cap="Assassin's Creed and Prince of Persia Sales (millions)"}
AC <- vgsales %>% filter(str_detect(vgsales$Name,("Assassin's"))) %>% 
  ggplot(aes(Global_Sales, Name, color = Platform)) + geom_point() +
  xlab("Global Sales") + ylab("Game") + xlim(0, 7)

PoP <- vgsales %>% filter(str_detect(vgsales$Name,c("Prince of", "Prince Of"))) %>% 
  ggplot(aes(Global_Sales, Name, color = Platform)) + geom_point() +
  xlab("Global Sales") + ylab("Game") + xlim(0, 7)

ggarrange(AC, PoP, ncol = 1)
```

* We can observe that there were **lesser PoP titles released compared to AC titles**. Also, only two games from the PoP franchise crossed sales of 1.5 million. On the other hand, AC has sold more than 2 million copies of most of their titles.

* This might explain why there are lesser games in PoP franchise compared to AC. UbiSoft slowly shifted their focus on the franchise that was more popular among gaming fans.

* Turns out after all, it's all about the money for the game producers... Fair enough from a business point of view. But I would've loved to have more PoP releases!

\newpage
## Publisher Performances -

* Next, I wanted to know how each Publisher performed in terms of number of copies sold. Which publisher sold most copies? This analysis can be extended to any Publisher on the dataset.

* The following table shows a summary of the **EA games Global Sales.**

```{r EASummary}
vgsales %>% filter(str_detect(vgsales$Publisher, "Electronic Arts")) %>%
  summarise(TotalTitles = n(),
            TotalCopiesSold = sum(Global_Sales),
            MeanGS = mean(Global_Sales),
            MedianGS = median(Global_Sales),
            MaxSold = max(Global_Sales),
            MinSold = min(Global_Sales)) %>% kable() %>%  kable_styling(full_width = FALSE)
```

```{r EAPlot}
EADensity <- vgsales %>% filter(str_detect(vgsales$Publisher, "Electronic Arts")) %>%
  ggplot(aes(x = Global_Sales, y = ..density..)) +
  geom_density(fill = "skyblue") + geom_vline(xintercept = mean(vgsales$Global_Sales),
  colour = "blue") + xlab("EA Games GlobalSales") + ylab("Density") + xlim(0, 15)
```

* The following table shows a summary of the **Activision games Global Sales.**

```{r ActivisionSummary}
vgsales %>% filter(str_detect(vgsales$Publisher, "Activision")) %>%
  summarise(TotalTitles = n(),
            TotalCopiesSold = sum(Global_Sales),
            MeanGS = mean(Global_Sales),
            MedianGS = median(Global_Sales),
            MaxSold = max(Global_Sales),
            MinSold = min(Global_Sales)) %>% kable() %>%  kable_styling(full_width = FALSE)
```

```{r ActivisionPlot}
ActivisionDensity <- vgsales %>% filter(str_detect(vgsales$Publisher, "Activision")) %>%
  ggplot(aes(x = Global_Sales, y = ..density..)) +
  geom_density(fill = "gold") + geom_vline(xintercept = mean(vgsales$Global_Sales),
  colour = "orange4") + xlab("Activision Games GlobalSales") + ylab("Density") + xlim(0, 15)
```

* The following table shows a summary of the **UbiSoft games Global Sales.**

```{r UbiSoftSummary}
vgsales %>% filter(str_detect(vgsales$Publisher, "Ubisoft")) %>%
  summarise(TotalTitles = n(),
            TotalCopiesSold = sum(Global_Sales),
            MeanGS = mean(Global_Sales),
            MedianGS = median(Global_Sales),
            MaxSold = max(Global_Sales),
            MinSold = min(Global_Sales)) %>% kable() %>%  kable_styling(full_width = FALSE)
```

```{r UbisoftPlot}
UbiSoftDensity <- vgsales %>% filter(str_detect(vgsales$Publisher, "Ubisoft")) %>%
  ggplot(aes(x = Global_Sales, y = ..density..)) +
  geom_density(fill = "greenyellow") + geom_vline(xintercept = mean(vgsales$Global_Sales),
  colour = "green4") + xlab("Ubisoft Games GlobalSales") + ylab("Density") + xlim(0, 15)
```

* The following table shows a summary of the **Sony games Global Sales.**

```{r SonySummary}
vgsales %>% filter(str_detect(vgsales$Publisher, "Sony Computer Entertainment")) %>%
  summarise(TotalTitles = n(),
            TotalCopiesSold = sum(Global_Sales),
            MeanGS = mean(Global_Sales),
            MedianGS = median(Global_Sales),
            MaxSold = max(Global_Sales),
            MinSold = min(Global_Sales)) %>% kable() %>%  kable_styling(full_width = FALSE)
```

```{r SonyPlot}
SonyDensity <- vgsales %>% filter(str_detect(vgsales$Publisher, "Sony Computer Entertainment")) %>%
  ggplot(aes(x = Global_Sales, y = ..density..)) +
  geom_density(fill = "indianred1") + geom_vline(xintercept = mean(vgsales$Global_Sales),
  colour = "red4") + xlab("Sony Games GlobalSales") + ylab("Density") + xlim(0, 15)
```

\newpage
**Publisher Global Sales Comparison -**

* This density plot helps us get an understanding as to which publisher sold how many copies.

```{r DensityPlots}
ggarrange(EADensity,ActivisionDensity, UbiSoftDensity, SonyDensity, ncol = 1)
```

* Sony seems to have the best mean sales followed by EA. Activision and UbiSoft have almost the same mean sales. Sony having sold the least number of titles still have an upper hand in the number of copies sold.

* With different questions asked, the answer is different. And it is debatable as to who was best.

\newpage
# **Conclusion -**

* This is just the start of answering questions about the data. There can be numerous questions asked and appropriate analysis conducted with suitable visual representations that can effectively answer the questions.

* Dig deep and find out answers to the most burning questions you have in mind, if you're a gaming enthusiast.

# **References -**

* [IDA reference](https://www.sciencedirect.com/science/article/pii/S0022522315017948#:~:text=Initial%20data%20analysis%20is%20the,of%20incorrect%20or%20misleading%20results.)

* [Correlation Plots Reference](http://www.sthda.com/english/wiki/correlation-test-between-two-variables-in-r#what-is-correlation-test)

* Wickham et al., (2019). Welcome to the tidyverse. Journal of Open Source Software, 4(43),
  1686, https://doi.org/10.21105/joss.01686
  
* Tierney N (2017). “visdat: Visualising Whole Data Frames.” _JOSS_, *2*(16), 355. doi:
10.21105/joss.00355 (URL: https://doi.org/10.21105/joss.00355), <URL:
http://dx.doi.org/10.21105/joss.00355>.

* Hao Zhu (2019). kableExtra: Construct Complex Table with 'kable' and Pipe Syntax. R
  package version 1.1.0. https://CRAN.R-project.org/package=kableExtra
  
* Alboukadel Kassambara (2020). ggpubr: 'ggplot2' Based Publication Ready Plots. R package
  version 0.4.0. https://CRAN.R-project.org/package=ggpub